{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301d82d3-c931-46eb-bce1-6cf3b548f178",
   "metadata": {},
   "source": [
    "### <span style=\"color: #477EB0; font-weight:700; font-size: 22px\">Imports</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f117c6-a017-4fd6-a66a-b695cb185ff0",
   "metadata": {},
   "source": [
    "General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccf69cc-a70c-41a5-9161-b20b45db790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3a241-e917-4766-b772-b848d0b51bc5",
   "metadata": {},
   "source": [
    "NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ca5c21-e4e4-4fea-9af6-0402d6b83f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d69da5f-bf6c-4a79-98a6-63125af906ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from better_profanity import profanity\n",
    "profanity.load_censor_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7484345a-cccf-48a9-a85f-4e2f3ac8cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_stamp = datetime.today().strftime('%d-%b-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369adea-83e3-413d-a85f-26c34694d3b7",
   "metadata": {},
   "source": [
    "### <span style=\"color: #477EB0; font-weight:700; font-size: 22px\">Read in Data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ee2173-99e4-47ca-b98a-4c3a1ae9ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/blizzard_data.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30d979f-24ee-4ec1-af09-81eae76e70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    html_raw = bs(f, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f382b-ea76-48d4-ac92-a2506fd8814b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #2c71b0; font-weight:600; font-size: 16px\">Find table headers</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37239bb6-67e6-4c24-923f-885e3babc731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 97 tables, headers are listed below\n",
      "I. What information do we collect?\n",
      "II. Why do we process your data?\n",
      "III. Data sharing and disclosure\n",
      "IV. What are tracking technologies, and how are they used?\n",
      "V. Auto-decision making/profiling\n",
      "VI. What level of security is applied to your personal information?\n",
      "VII. Right of Access\n",
      "VIII. More Information\n",
      "Battle.net Account\n",
      "Home Address\n",
      "Account Link\n",
      "Account Link\n",
      "Account Link\n",
      "Security\n",
      "Gameplay History\n",
      "Beta Opt In Details\n",
      "Wallet Information\n",
      "Current Balances\n",
      "Ledger Entries\n",
      "Orders\n",
      "User Settings\n",
      "US Block List\n",
      "US Club List\n",
      "US Friends\n",
      "EU Block List\n",
      "EU Club List\n",
      "EU Friends\n",
      "KR Block List\n",
      "KR Club List\n",
      "KR Friends\n",
      "PTR Block List\n",
      "PTR Club List\n",
      "PTR Friends\n",
      "Battle.net Whisper Chat\n",
      "Overwatch Chat\n",
      "User Data By Region\n",
      "Penalty History - EU\n",
      "Penalty History - KR\n",
      "Penalty History - TW\n",
      "Penalty History - US\n",
      "Activity History\n",
      "Restriction History\n",
      "Characters\n",
      "Chat History\n",
      "Crafting Orders\n",
      "Player\n",
      "Player Lootbox\n",
      "Player Lootbox Unlock\n",
      "Player Owl Token Spend\n",
      "Player Progression Badge\n",
      "Player Progression Emblem\n",
      "Player Map Stat\n",
      "Player All Hero Stat\n",
      "Hero\n",
      "Hero Stat\n",
      "Achievement\n",
      "Player Challenge V2\n",
      "Player Challenge Stat V2\n",
      "Player Celebration\n",
      "Player Ruleset\n",
      "Player Ranked Role Data\n",
      "Player Custom Game Options\n",
      "Player Endorsements\n",
      "Player Saved Match\n",
      "Player Consumable\n",
      "Player Battle Pass\n",
      "Player Bpay Product Add\n",
      "Player Ranked Match History\n",
      "Player Event Currency Conversion\n",
      "Player\n",
      "Player\n",
      "Player\n",
      "Player Lootbox\n",
      "Player Lootbox Unlock\n",
      "Player Owl Token Spend\n",
      "Player Progression Badge\n",
      "Player Progression Emblem\n",
      "Player Map Stat\n",
      "Player All Hero Stat\n",
      "Hero\n",
      "Hero Stat\n",
      "Achievement\n",
      "Player Challenge V2\n",
      "Player Challenge Stat V2\n",
      "Player Celebration\n",
      "Player Ruleset\n",
      "Player Ranked Role Data\n",
      "Player Custom Game Options\n",
      "Player Endorsements\n",
      "Player Saved Match\n",
      "Player Consumable\n",
      "Player Battle Pass\n",
      "Player Bpay Product Add\n",
      "Player Ranked Match History\n",
      "Player Event Currency Conversion\n",
      "Player\n",
      "Characters\n"
     ]
    }
   ],
   "source": [
    "headers = html_raw.find_all('h2')\n",
    "print(f'Found {len(headers)} tables, headers are listed below')\n",
    "[print(x.text) for x in headers];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a6fac-ffcc-42d1-a649-ece34e0010c1",
   "metadata": {},
   "source": [
    "### <span style=\"color: #477EB0; font-weight:700; font-size: 22px\">Parse Data from HTML Tables</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c6a35-dbdd-44c1-9776-404f16f907ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #2c71b0; font-weight:600; font-size: 16px\">Activity History (Logins and Logouts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7fb9ae-f970-447d-a23d-799608820147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get header object in html\n",
    "header_obj = html_raw.find(string='Activity History')\n",
    "# find first table after the header \n",
    "html_table = header_obj.find_next('table')\n",
    "# parse the table\n",
    "activity_history_df = pd.concat(pd.read_html(StringIO(str(html_table))))\n",
    "activity_history_df.rename(columns=lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "activity_history_df.rename(columns={'time_(utc)':'time',\n",
    "                                    'geo-ip_location':'location'}, inplace=True)\n",
    "activity_history_df['time'] = pd.to_datetime(activity_history_df['time'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5c87a-1135-415b-a78c-c2f4c0515180",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #2c71b0; font-weight:600; font-size: 16px\">Ranked Match History</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8974032-c84a-40d0-a267-0f261f957882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get header object in html\n",
    "header_obj = html_raw.find(string='Player Ranked Match History')\n",
    "# find first table after the header \n",
    "html_table = header_obj.find_next('table')\n",
    "# parse the table\n",
    "match_history_df = pd.concat(pd.read_html(StringIO(str(html_table))))\n",
    "match_history_df.rename(columns=lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "# remove invalid rows\n",
    "invalid_rows = match_history_df[match_history_df['leaderboard_region']=='INVALID']\n",
    "match_history_df.drop(index=invalid_rows.index, inplace=True)\n",
    "match_history_df.reset_index(drop=True, inplace=True)\n",
    "match_history_df['match_start_date'] = match_history_df['start_time_epoch_seconds'].apply(lambda x: datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a519e9-7089-48a1-8479-4d6203aaed46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #2c71b0; font-weight:600; font-size: 16px\">Battle Pass Progression</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20747755-88c5-49cd-a5ae-f251d32b4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrowe-hibbert\\AppData\\Local\\Temp\\ipykernel_16264\\371637749.py:6: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  battle_pass_df = pd.concat(pd.read_html(str(html_table)))\n"
     ]
    }
   ],
   "source": [
    "# get header object in html\n",
    "header_obj = html_raw.find(string='Player Battle Pass')\n",
    "# find first table after the header \n",
    "html_table = header_obj.find_next('table')\n",
    "# parse the table\n",
    "battle_pass_df = pd.concat(pd.read_html(str(html_table)))\n",
    "battle_pass_df.rename(columns=lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "battle_pass_df['last_claim_time'] = battle_pass_df['last_claim_time'].apply(lambda x: datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cff65-8ae4-41eb-a145-f4c9b1981c0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #2c71b0; font-weight:600; font-size: 16px\">Coin Ledger</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5352fc9-a1f2-400d-a348-2bdaf319ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get header object in html\n",
    "header_obj = html_raw.find(string='Ledger Entries')\n",
    "# find first table after the header \n",
    "html_table = header_obj.find_next('table')\n",
    "# parse the table\n",
    "coin_ledger_df = pd.concat(pd.read_html(StringIO(str(html_table))))\n",
    "coin_ledger_df.rename(columns=lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "coin_ledger_df['timestamp'] = pd.to_datetime(coin_ledger_df['timestamp'], format='%m/%d/%Y %H:%M:%S')\n",
    "coin_ledger_df['week_start'] = coin_ledger_df['timestamp'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "bal = 0\n",
    "for i, row in coin_ledger_df.sort_values('timestamp').iterrows():\n",
    "    bal += row['amount']\n",
    "    coin_ledger_df.at[i, 'balance'] = bal\n",
    "coin_ledger_df.sort_values('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c71152-94bf-4912-ad8f-2fb929bb3621",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #2c71b0; font-weight:600; font-size: 16px\">In-Game Chat History</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90da5df6-2397-4048-b9e6-75f211bb2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get header object in html\n",
    "header_obj = html_raw.find(string='Overwatch Chat')\n",
    "# find first table after the header \n",
    "html_table = header_obj.find_next('table')\n",
    "# parse the table\n",
    "chat_history_df = pd.concat(pd.read_html(StringIO(str(html_table))))\n",
    "chat_history_df.rename(columns=lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "chat_history_df['time'] = chat_history_df['time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "chat_history_df['message_id'] = chat_history_df.index.tolist() # assign each message a unique id\n",
    "chat_history_df.sort_values('time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e326c9f-782b-468b-ba59-eb408b7d38f7",
   "metadata": {},
   "source": [
    "### <span style=\"color: #d63031; font-weight:700; font-size: 22px\">Chat Data NLP Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a060acdd-ab6a-4fbb-a087-7b7ecf356615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat history start: 30 Dec 2023\n",
      "chat history end: 28 Feb 2024\n",
      "period:  60 days 02:09:58.173000\n"
     ]
    }
   ],
   "source": [
    "print('chat history start:', chat_history_df['time'].min().strftime('%d %b %Y'))\n",
    "print('chat history end:', chat_history_df['time'].max().strftime('%d %b %Y'))\n",
    "print('period: ', chat_history_df['time'].max() - chat_history_df['time'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d1509d1-8370-411a-bf7d-47f669ac4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of {message id : message text}\n",
    "message_dict = chat_history_df.set_index('message_id')['message'].to_dict()\n",
    "# create a list of message text\n",
    "messages_list = list(message_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241b770-4ae5-4ad7-b11a-4342f1e8961d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #d63031; font-weight:600; font-size: 16px\">Identify Profanity in Messages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be6e496c-c25b-4a24-bc48-cb2eb6332ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_badwords = ['ez', 'ur nana']\n",
    "profanity.add_censor_words(custom_badwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ec952d-57fc-44c0-9005-a9d4e7411340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for profanity\n",
    "chat_history_df['contains_profanity'] = chat_history_df['message'].apply(profanity.contains_profanity)\n",
    "# apply profanity filter (used to extract the profane word itself)\n",
    "chat_history_df['censored_message'] = chat_history_df['message'].apply(profanity.censor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82935589-5008-4a03-9851-d2ce63e5e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove false positives\n",
    "false_positives = [ # list of messages which I feel should not be included\n",
    "    'whats a kind to a god?',\n",
    "    'ur lucios throwing lmao',\n",
    "    'ur front line lmao',\n",
    "    'fr fr on god?',\n",
    "    'lmao',\n",
    "    'sniper kill',\n",
    "    '*zarya'\n",
    "]\n",
    "chat_history_df['contains_profanity'] = chat_history_df[['contains_profanity', 'message']].apply(lambda x: False if x.iloc[1] in false_positives else x.iloc[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5946a8d0-c825-4e27-beee-6bc458e31e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the profane word identified by getting the index of the asterisks in the censored message\n",
    "# e.g. Raw Message: \"thats bullshit\"; Censored: \"thats ********\"\n",
    "# Start index of \"*\": 6;\n",
    "# End index of \"*\": 0 (index from end of the string)\n",
    "chat_history_df['censored_start'] = chat_history_df[['contains_profanity', 'censored_message']].apply(lambda x: x.iloc[1].index('*') if x.iloc[0] else None, axis=1)\n",
    "chat_history_df['censored_end'] = chat_history_df[['contains_profanity', 'censored_message']].apply(lambda x: x.iloc[1][::-1].index('*') if x.iloc[0] else None, axis=1)\n",
    "# convert index from end of string to index from start of string \n",
    "chat_history_df['censored_end'] = chat_history_df[['censored_end', 'message']].apply(lambda x: len(x.iloc[1]) if x.iloc[0]==0 else len(x.iloc[1])-x.iloc[0], axis=1)\n",
    "# extract the profane word\n",
    "chat_history_df['profanity'] = chat_history_df[['contains_profanity', 'message', 'censored_start', 'censored_end']].apply(lambda x: None if not x.iloc[0] else x.iloc[1][int(x.iloc[2]):int(x.iloc[3])], axis=1)\n",
    "# fill nulls NOT NEEDED\n",
    "# chat_history_df['profanity'] = chat_history_df[['contains_profanity', 'profanity']].apply(lambda x: x.iloc[1] if x.iloc[0] else None, axis=1)\n",
    "# drop calculation columns\n",
    "chat_history_df.drop(columns=['censored_message', 'censored_start', 'censored_end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adb5222d-8d63-42e6-b986-5ad2d6163582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_df[chat_history_df['contains_profanity']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d338db1a-5c87-48a8-8914-e9c5eb0800af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>message</th>\n",
       "      <th>message_id</th>\n",
       "      <th>contains_profanity</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2024-02-19 00:26:46.703</td>\n",
       "      <td>no winton</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2024-02-10 21:44:32.816</td>\n",
       "      <td>gg</td>\n",
       "      <td>356</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2024-02-27 22:37:46.613</td>\n",
       "      <td>^^</td>\n",
       "      <td>514</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2024-01-08 22:52:59.832</td>\n",
       "      <td>tank diff</td>\n",
       "      <td>124</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2024-02-02 22:33:11.164</td>\n",
       "      <td>lol ok cool</td>\n",
       "      <td>268</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2024-02-21 23:11:25.511</td>\n",
       "      <td>whats a kind to a god?</td>\n",
       "      <td>444</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2024-01-08 22:37:15.414</td>\n",
       "      <td>coolio</td>\n",
       "      <td>121</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2024-01-03 20:45:36.160</td>\n",
       "      <td>pizaa on me</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2024-02-24 00:46:40.117</td>\n",
       "      <td>im digital</td>\n",
       "      <td>452</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2024-02-24 00:45:45.095</td>\n",
       "      <td>choose your time wisely</td>\n",
       "      <td>449</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time                  message  message_id  \\\n",
       "403 2024-02-19 00:26:46.703                no winton         403   \n",
       "356 2024-02-10 21:44:32.816                       gg         356   \n",
       "514 2024-02-27 22:37:46.613                       ^^         514   \n",
       "124 2024-01-08 22:52:59.832                tank diff         124   \n",
       "268 2024-02-02 22:33:11.164              lol ok cool         268   \n",
       "444 2024-02-21 23:11:25.511   whats a kind to a god?         444   \n",
       "121 2024-01-08 22:37:15.414                   coolio         121   \n",
       "88  2024-01-03 20:45:36.160              pizaa on me          88   \n",
       "452 2024-02-24 00:46:40.117               im digital         452   \n",
       "449 2024-02-24 00:45:45.095  choose your time wisely         449   \n",
       "\n",
       "     contains_profanity profanity  \n",
       "403               False      None  \n",
       "356               False      None  \n",
       "514               False      None  \n",
       "124               False      None  \n",
       "268               False      None  \n",
       "444               False      None  \n",
       "121               False      None  \n",
       "88                False      None  \n",
       "452               False      None  \n",
       "449               False      None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_df[['time', 'message', 'message_id', 'contains_profanity', 'profanity']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7dab3b-a00a-441e-97b4-8833e45e0d50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #d63031; font-weight:600; font-size: 16px\">N-gram Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46264b16-c199-4690-ac66-a55ad2e4cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d7eed4-8cbe-4939-822e-eb134be40414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate n-grams\n",
    "def generate_ngrams(messages, n):\n",
    "    ngrams_list = []\n",
    "    for message in messages:\n",
    "        tokens = tokenizer.tokenize(message)\n",
    "        ngrams_list.extend(ngrams(tokens, n))\n",
    "    return ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efc7f49e-5806-437c-90bb-2346f6336907",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ngrams = []\n",
    "for i in range(4):\n",
    "    ngrams_list = generate_ngrams(messages_list, i+1)\n",
    "    ngram_frequencies = Counter(ngrams_list)\n",
    "    nested_list = [[n,count] for n, count in zip(list(ngram_frequencies.keys()), list(ngram_frequencies.values()))]\n",
    "    all_ngrams.extend(nested_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5143f074-a4dd-42ef-93b6-6874494ecdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_df = pd.DataFrame(all_ngrams, columns=['tokens', 'count'])\n",
    "ngram_df['number_of_words'] = ngram_df['tokens'].str.len()\n",
    "ngram_df['phrase'] = ngram_df['tokens'].str.join(' ')\n",
    "ngram_df.sort_values('count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a49efb7b-f909-4bbd-8eb2-0644a449097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ngrams only seen once\n",
    "drop_seen_once = ngram_df[ngram_df['count']==1].index\n",
    "ngram_df.drop(index=drop_seen_once, inplace=True)\n",
    "ngram_df.reset_index(drop=True, inplace=True)\n",
    "# try to adjust count by n_words as longer ngrams are less likely \n",
    "ngram_df['score'] = ngram_df['count'] * (ngram_df['number_of_words'] *1.3)\n",
    "ngram_df['rank'] = ngram_df['score'].rank(method='dense', ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c20b329-8a99-4118-96fd-b3f3192f1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop word uni-grams\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_unigrams = ngram_df[ngram_df['phrase'].isin(stopword_list)].index\n",
    "ngram_df.drop(index=stopword_unigrams, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f003197-5069-4f30-bc6f-a11418e977bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_df.sort_values('score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b368295e-82bf-46b1-b4fb-c64dd8fe0149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>count</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>(why, would)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>why would</td>\n",
       "      <td>5.2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>(on, the)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>on the</td>\n",
       "      <td>5.2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>(we, can)</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>we can</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>(tank, diff)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>tank diff</td>\n",
       "      <td>7.8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>(is, my)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>is my</td>\n",
       "      <td>5.2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tokens  count  number_of_words     phrase  score  rank\n",
       "163  (why, would)      2                2  why would    5.2    14\n",
       "173     (on, the)      2                2     on the    5.2    14\n",
       "53      (we, can)      4                2     we can   10.4    10\n",
       "65   (tank, diff)      3                2  tank diff    7.8    12\n",
       "128      (is, my)      2                2      is my    5.2    14"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df[ngram_df['number_of_words']==2].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94393320-d23b-432d-80cc-82b30fe04de9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #d63031; font-weight:600; font-size: 16px\">Sentiment Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c4c0503-a93b-4507-a251-b60f3ac69f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis\n",
    "def analyze_sentiments(messages: dict):\n",
    "    sentiments = []\n",
    "    for i, message in messages.items():\n",
    "        blob = TextBlob(message)\n",
    "        # Polarity ranges from -1 (negative) to 1 (positive)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        # Subjectivity ranges from 0 (objective) to 1 (subjective)\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "        sentiments.append((i, message, polarity, subjectivity))\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "512af5bc-8737-4540-abd6-a087baf5dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweak some of the common acronyms used to improve accuracy\n",
    "cleaned_message_dict = {k:re.sub('lol|lmao|aha', '', x) for k,x in message_dict.items()}\n",
    "cleaned_message_dict = {k:re.sub('gl hf', 'good luck, have fun', x) for k,x in cleaned_message_dict.items()}\n",
    "cleaned_message_dict = {k:re.sub('gg', 'good game', x) for k,x in cleaned_message_dict.items()}\n",
    "\n",
    "message_sentiments = analyze_sentiments(cleaned_message_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87abcbc2-464b-41be-a967-c0529ff260aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_messages_df = pd.DataFrame(message_sentiments, columns=['message_id', 'message_nlp_cleaned', 'polarity', 'subjectivity'])\n",
    "sentiment_df = sentiment_messages_df.groupby(['message_nlp_cleaned'], as_index=False).agg({'polarity':'mean', 'subjectivity':'mean', 'message_id':set})\n",
    "sentiment_df.sort_values('polarity', ascending=False, inplace=True)\n",
    "sentiment_df.drop(columns=['message_nlp_cleaned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d08cb7a0-d8b2-490d-aec5-72e2a8d0c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join sentiment scores to message data\n",
    "chat_history_sentiment = chat_history_df.merge(sentiment_df.explode('message_id'), how='left', on='message_id', validate='m:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80aed43-5df0-4c85-9244-d1e8af3a8412",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #d63031; font-weight:600; font-size: 16px\">Fill Missing Dates (frequency: day)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf5c0439-d0c5-4500-a49e-f961b22aab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rows for every day from the min date to max date - this will prevent issues later in tableau\n",
    "# Tableau is picky about interpolating dates (e.g. for a daily chart you need a data point each day even if 0)\n",
    "daily_date_range = [d.date() for d in pd.date_range(start=chat_history_df['time'].min(), end=chat_history_df['time'].max(), freq='d')]\n",
    "date_to_add = []\n",
    "for d in daily_date_range:\n",
    "    in_dataset_check = chat_history_df[chat_history_df['time'].dt.date == d]\n",
    "    if in_dataset_check.empty:\n",
    "        date_to_add.append(pd.to_datetime(d))\n",
    "# create data frame of \"empty rows\"\n",
    "daily_fill_data = pd.DataFrame(data=date_to_add, columns=['time'])\n",
    "daily_fill_data['message_id'] = None\n",
    "daily_fill_data['contains_profanity'] = False\n",
    "daily_fill_data['profanity'] = None\n",
    "daily_fill_data['polarity'] = 0.0\n",
    "daily_fill_data['subjectivity'] = 0.0\n",
    "# join chat data and empty rows\n",
    "filled_chat_history = pd.concat([chat_history_sentiment, daily_fill_data])\n",
    "filled_chat_history['week_start'] = filled_chat_history['time'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a071ae-020d-4abf-988f-47818d3ed251",
   "metadata": {},
   "source": [
    "### <span style=\"color: #349857; font-weight:700; font-size: 22px\">Activity Data Prep</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed69c5-560a-4d83-86d9-64cd36214102",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #349857; font-weight:600; font-size: 16px\">Create login event data (wide dataset)</span>\n",
    "This code converts the data from long form (one event per row) to a wide form (LOGIN and LOGOUTS time in each row).\n",
    "\n",
    "This requires linking up paired events e.g. LOGIN  at 10AM should be paired with the first subsequent LOGOUT).\n",
    "\n",
    "In some cases there are missing events (e.g. no LOGOUT from the same IP as the LOGIN). When no LOGOUT is found,\n",
    "the LOGOUT time is added as `missing_data_session_length` hours after LOGIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47e71f58-cc6b-4ca4-859d-05a3620afb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log with no logout on: 2023-12-20 21:37:07, using average session length.\n",
      "Log with no logout on: 2024-01-09 21:27:24, using average session length.\n"
     ]
    }
   ],
   "source": [
    "logins = activity_history_df[activity_history_df['activity_type']=='Logged into Overwatch'].reset_index(drop=True)\n",
    "logouts = activity_history_df[activity_history_df['activity_type']=='Logged out of Overwatch'].copy()\n",
    "\n",
    "missing_data_session_length = 2.3 # assumed length of sessions with no log out event\n",
    "log_events_data = []\n",
    "for i, row in logins.iterrows():\n",
    "    login_time = row['time']\n",
    "    logouts_after = logouts[logouts['time'] >= login_time] # all logout events after the login\n",
    "    first_logout = logouts_after[logouts_after['time']==logouts_after['time'].min()] # earliest logout after the login\n",
    "    first_logout_same_ip = first_logout[first_logout['ip_address']==row['ip_address']] # IP address of logout must be equal to login IP\n",
    "    if first_logout_same_ip.empty:\n",
    "        print(f'Log with no logout on: {login_time}, using average session length.')\n",
    "        logout_time = login_time + timedelta(hours=missing_data_session_length) # assume session length\n",
    "    else:\n",
    "        logout_time = first_logout_same_ip.iloc[0]['time'] # get logout time\n",
    "    log_events_data.append([i, login_time, logout_time]) # store session values\n",
    "# create wide data set\n",
    "log_events_df = pd.DataFrame(log_events_data, columns=['id', 'login_time', 'logout_time'])\n",
    "log_events_df['duration_seconds'] = (log_events_df['logout_time'] - log_events_df['login_time']).dt.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f1bb07a-9d40-4da2-a230-84e95719274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually edit anomalies (these are specific occasions when I left my PC turned on with Overwatch running - racking up a very long session length)\n",
    "# I adjust these down to `missing_data_session_length` hours\n",
    "# anomaly one\n",
    "edit_date_in = datetime.strptime('2023-12-16 01:25:04', '%Y-%m-%d %H:%M:%S')\n",
    "edit_date_out = datetime.strptime('2023-12-16', '%Y-%m-%d').date()\n",
    "edit_date = (log_events_df['login_time'] == edit_date_in) & (log_events_df['logout_time'].dt.date == edit_date_out)\n",
    "log_events_df.at[log_events_df[edit_date].index[0], 'duration_seconds'] = (missing_data_session_length * 60)\n",
    "# anomaly two \n",
    "edit_date_in = datetime.strptime('2023-07-15 19:34:14', '%Y-%m-%d %H:%M:%S')\n",
    "edit_date_out = datetime.strptime('2023-07-16', '%Y-%m-%d').date()\n",
    "edit_date = (log_events_df['login_time'] == edit_date_in) & (log_events_df['logout_time'].dt.date == edit_date_out)\n",
    "log_events_df.at[log_events_df[edit_date].index[0], 'duration_seconds'] = (missing_data_session_length * 60)\n",
    "# anomaly three\n",
    "edit_date_in = datetime.strptime('2024-02-26 01:44:29', '%Y-%m-%d %H:%M:%S')\n",
    "edit_date_out = datetime.strptime('2024-02-26', '%Y-%m-%d').date()\n",
    "edit_date = (log_events_df['login_time'] == edit_date_in) & (log_events_df['logout_time'].dt.date == edit_date_out)\n",
    "log_events_df.at[log_events_df[edit_date].index[0], 'duration_seconds'] = (missing_data_session_length * 60)\n",
    "# anomaly four\n",
    "edit_date_in = datetime.strptime('2024-02-04 01:17:22', '%Y-%m-%d %H:%M:%S')\n",
    "edit_date_out = datetime.strptime('2024-02-05', '%Y-%m-%d').date()\n",
    "edit_date = (log_events_df['login_time'] == edit_date_in) & (log_events_df['logout_time'].dt.date == edit_date_out)\n",
    "log_events_df.at[log_events_df[edit_date].index[0], 'duration_seconds'] = (missing_data_session_length * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352aaa6-730f-43d6-a993-63f9a385ac61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #349857; font-weight:600; font-size: 16px\">Create weekly duration data (long)</span>\n",
    "This code aggregates the session length to a weekly frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2031e618-9318-40f6-90ad-67a40efea009",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_datetime_range = pd.date_range(start=log_events_df['login_time'].min(), end=datetime.strptime('2024-06-01', '%Y-%m-%d'), freq='w-mon')\n",
    "weekly_dates = [d.date() for d in weekly_datetime_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9b1f8e4-5ace-44b5-8716-07f7d727f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "login_weekly_durations = {}\n",
    "for i, d in enumerate(weekly_dates):\n",
    "    login_on_after_d = log_events_df['login_time'].dt.date >= d\n",
    "    login_before_week_end = log_events_df['login_time'].dt.date < (d + timedelta(days=7))\n",
    "    login_during_week = log_events_df[(login_on_after_d) & (login_before_week_end)].copy()\n",
    "    login_weekly_durations[d] = login_during_week['duration_seconds'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a951bf3-47bc-46f6-a194-8232d2b2179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_durations_df = pd.DataFrame(login_weekly_durations.values(), index=login_weekly_durations.keys()).reset_index()\n",
    "weekly_durations_df.columns = ['Week', 'duration_seconds']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f968ef-a665-4706-966f-1242ed1b41d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <span style=\"color: #349857; font-weight:600; font-size: 16px\">Create Hour of Login Data</span>\n",
    "This code breaks down the number of logins and logouts by hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a6efafe-b917-4245-ae20-566a18e10962",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_of_activity = log_events_df.copy()\n",
    "hour_of_activity['login_hour'] = hour_of_activity['login_time'].dt.hour\n",
    "hour_of_activity['logout_hour'] = hour_of_activity['logout_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79d7e08a-5402-4f06-95ba-6278debd1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_of_login = hour_of_activity.groupby(['login_hour'], as_index=False)['id'].nunique()\n",
    "hour_of_login.rename(columns={'id':'logins',\n",
    "                              'login_hour':'hour'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2f03299-27c0-4b7e-b8cd-6d8a358aa3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_of_logout = hour_of_activity.groupby(['logout_hour'], as_index=False)['id'].nunique()\n",
    "hour_of_logout.rename(columns={'id':'logouts',\n",
    "                              'logout_hour':'hour'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86b18e8d-a0dd-4df5-822e-108d8c4017e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_by_hour_df = hour_of_login.merge(hour_of_logout, on='hour', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b04d2fb-17be-45be-b653-7aa87e21d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_to_fill = [h for h in range(24) if h not in activity_by_hour_df['hour'].unique()]\n",
    "for h in hours_to_fill:\n",
    "    activity_by_hour_df.at[len(activity_by_hour_df), 'hour'] = h\n",
    "activity_by_hour_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07332dea-b2fd-417b-83f4-fa9be7a20364",
   "metadata": {},
   "source": [
    "### <span style=\"color: #349857; font-weight:700; font-size: 22px\">Output Data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d0c63-9432-40b6-9d46-d69314fde637",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">Coin Ledger (unused in dashboard)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6075962-d6cf-4575-87b2-78e62797c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ledger_df.to_csv(f'output/coin_ledger.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050971c-a19c-43a5-938e-b193a492ad80",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">Battlepass Progression</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5b9b812-328c-4841-9ebf-e108c285426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "battle_pass_df.to_csv(f'output/battle_pass.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca0a4b-0e58-4a07-a4b2-c66f8a024e93",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">Chat History</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee12f660-f8df-43f3-a28e-91b179fd5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_chat_history.to_csv(f'output/chat_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f693e1-ff32-4977-89cc-c49a139e82e0",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">N-Grams</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4770c9a8-63d4-4432-bffa-9c2e0569add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_df.to_csv(f'output/chat_n_grams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4821e5-07e0-4fbf-91e4-b1012b48535a",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">Activity History - Login/Out Data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ebb6081-c870-4215-8cd7-e1dc3d6013b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_events_df.to_csv(f'output/overwatch_playtime.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0eb684-b9b7-499d-9b2d-c2caa0cc932c",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">Activity History - Weekly Timeseries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bbb51590-1e6f-4ee9-9ec9-3fa3c9294143",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_durations_df.to_csv(f'output/overwatch_weekly_playtime.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d494986-452d-415f-b37f-cb43ae8e633a",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #349857; font-weight:500; font-size: 15px\">Activity History - # Login/Out by Hour (unused in dashboard)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbe8bff5-8918-4c0a-b212-8945c64a96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_by_hour_df.to_csv(f'output/overwatch_activity_by_hour.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
